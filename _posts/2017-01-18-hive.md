---
layout: post
title: hive
category: 大数据
---

####hive的安装
#### 前提：已经安装了hadoop的master机器 
   
####hive下载：  
http://hive.apache.org/downloads.html  
需要配合安装的hadoop版本选择hive版本，我的测试环境hadoop版本是：2.7.3，hive下载的版本是2.1.1


####解压
tar -zvxf 名称  
解压后，将HIVE的环境变量，加入/etc/profile  
export $HIVE=hive的路径  
export PATH=$PATH:$HIVE/bin

####修改配置文件
$HIVE/conf路径下  
cp hive-env.sh.template hive-env.sh  
cp hive-default.xml.template hive-site.xml  
cp hive-log4j2.properties.template hive-log4j2.properties  
cp hive-exec-log4j2.properties.template hive-exec-log4j2.properties  


hive-env.sh  

hive-site.xml  
 <property>
  <name>hive.metastore.warehouse.dir</name> //这个参数是存储hive数据(表)的目录，我们需要在配置之前新建hdfs目录，并授权
  <value>/home/hadoop/hive/warehouse</value>
  <description>location of default database for the warehouse</description>
  </property>

[hadoop@master ~]$ hadoop fs -mkdir -p /home/hadoop/hive/warehouse
[hadoop@master ~]$ hadoop fs -chmod 777 /home/hadoop/hive/warehouse

 <property>
  <name>hive.metastore.uris</name>
  <value>jdbc:oracle:thin:@192.168.1.12:1521/test</value>//配置远程的数据库连接
   <description>Thrift URI for the remote metastore. Used by metastore client to connect to remote metastore.</description>
  </property>
hive-log4j2.properties   
hive-exec-log4j2.properties 

